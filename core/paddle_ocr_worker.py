#!/usr/bin/env python3
"""
PaddleOCRè¯†åˆ«å·¥ä½œçº¿ç¨‹æ¨¡å— - ä½¿ç”¨æ‚¨è®­ç»ƒçš„ä¸“ç”¨æ¨¡å‹
é’ˆå¯¹æœºæ¢°å›¾çº¸è¿›è¡Œæ·±åº¦ä¼˜åŒ–çš„OCRè¯†åˆ«ç³»ç»Ÿ
"""

import sys
import os
import cv2
import numpy as np
import logging
import re
import time
from datetime import datetime
from PySide6.QtCore import QObject, QRunnable, Signal
from typing import List, Dict, Tuple, Optional, Any

# é…ç½®æ—¥å¿—è®°å½•å™¨
logger = logging.getLogger('OCR_Performance')
logger.setLevel(logging.INFO)
# åˆ›å»ºä¸€ä¸ªæ–‡ä»¶å¤„ç†å™¨
ocr_log_path = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'ocr_performance.log')
file_handler = logging.FileHandler(ocr_log_path, encoding='utf-8')
file_handler.setLevel(logging.INFO)
# åˆ›å»ºä¸€ä¸ªç®€æ´çš„æ ¼å¼åŒ–å™¨ - åªè®°å½•æ—¶é—´ã€æ–‡ä»¶åã€å¤§å°å’ŒOCRæ—¶é—´
formatter = logging.Formatter('%(asctime)s - %(message)s')
file_handler.setFormatter(formatter)
# å°†å¤„ç†å™¨æ·»åŠ åˆ°æ—¥å¿—è®°å½•å™¨
logger.addHandler(file_handler)

# æ·»åŠ PaddleOCRè·¯å¾„ - ä½¿ç”¨æœ¬åœ°æ–‡ä»¶
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.insert(0, parent_dir)

# è®¾ç½®ä¸infer_tu2.pyç›¸åŒçš„GPUç¯å¢ƒå˜é‡
os.environ["FLAGS_allocator_strategy"] = 'auto_growth'
os.environ["CUDA_VISIBLE_DEVICES"] = "0"

# å¯¼å…¥PaddleOCRç›¸å…³æ¨¡å—
try:
    import paddle
    PADDLE_AVAILABLE = True
    
    # æ£€æµ‹GPUæ”¯æŒ
    HAS_GPU_SUPPORT = False
    try:
        if paddle.is_compiled_with_cuda():
            gpu_count = paddle.device.cuda.device_count()
            HAS_GPU_SUPPORT = gpu_count > 0
            if HAS_GPU_SUPPORT:
                print(f"âœ… æ£€æµ‹åˆ°{gpu_count}ä¸ªå¯ç”¨GPU")
            else:
                print("âš ï¸ å·²ç¼–è¯‘CUDAæ”¯æŒï¼Œä½†æœªæ£€æµ‹åˆ°å¯ç”¨GPUè®¾å¤‡")
        else:
            print("âš ï¸ PaddlePaddleæœªä½¿ç”¨CUDAç¼–è¯‘")
    except Exception as e:
        print(f"âš ï¸ æ£€æµ‹GPUæ”¯æŒæ—¶å‡ºé”™: {e}")
        HAS_GPU_SUPPORT = False
    
    print("âœ… PaddleOCRæ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    logging.warning(f"PaddleOCR not available: {e}")
    PADDLE_AVAILABLE = False
    HAS_GPU_SUPPORT = False
    print(f"âŒ PaddleOCRæ¨¡å—å¯¼å…¥å¤±è´¥: {e}")


class PaddleOCRWorkerSignals(QObject):
    """PaddleOCRå·¥ä½œçº¿ç¨‹ä¿¡å·"""
    finished = Signal(list)
    progress = Signal(int)
    error = Signal(str)


class PaddleOCRWorker(QRunnable):
    """PaddleOCRè¯†åˆ«å·¥ä½œçº¿ç¨‹ - ä½¿ç”¨æ‚¨è®­ç»ƒçš„ä¸“ç”¨æ¨¡å‹"""
    
    def __init__(self, image_path: str, languages: list = ['ch_sim', 'en'], masked_regions: list = None, force_cpu: bool = False, cpu_threads: int = 8):
        super().__init__()
        self.image_path = image_path
        self.languages = languages
        self.masked_regions = masked_regions or []
        self.signals = PaddleOCRWorkerSignals()
        self.force_cpu = force_cpu
        self.cpu_threads = cpu_threads
        
        self.config_dict = {
            "ocr_det_config": os.path.join(parent_dir, "model", "det_best_model", "config.yml"),
            "ocr_rec_config": os.path.join(parent_dir, "configs", "rec", "PP-OCRv4", "ch_PP-OCRv4_rec_hgnet.yml")
        }
        
        self.ocr_processor = None
    
    def run(self):
        """æ‰§è¡ŒPaddleOCRè¯†åˆ«"""
        if not PADDLE_AVAILABLE:
            self.signals.error.emit("PaddleOCRåŠŸèƒ½æœªå¯ç”¨ï¼Œè¯·å®‰è£…PaddlePaddle")
            return

        try:
            start_time = time.time()
            start_datetime = datetime.now()
            print(f"\nğŸ“‹ OCRä»»åŠ¡å¼€å§‹æ—¶é—´: {start_datetime.strftime('%Y-%m-%d %H:%M:%S')}")
            print(f"ğŸ“„ å¤„ç†æ–‡ä»¶: {os.path.basename(self.image_path)}")
            # ä»…è®°å½•å¤„ç†æ–‡ä»¶è·¯å¾„
            # logger.info(f"OCRä»»åŠ¡å¼€å§‹ - æ–‡ä»¶: {self.image_path}")

            os.environ["OMP_NUM_THREADS"] = str(self.cpu_threads)
            os.environ["KMP_AFFINITY"] = "granularity=fine,compact,1,0"

            use_gpu = HAS_GPU_SUPPORT and not self.force_cpu
            if use_gpu:
                print("ğŸš€ ä½¿ç”¨GPUè¿›è¡ŒPaddleOCRè¯†åˆ«")
                # logger.info("ä½¿ç”¨GPUè¿›è¡ŒOCRè¯†åˆ«")
            else:
                print(f"ğŸš€ ä½¿ç”¨CPUè¿›è¡ŒPaddleOCRè¯†åˆ« ({self.cpu_threads}çº¿ç¨‹)" + (" (å¼ºåˆ¶CPUæ¨¡å¼)" if self.force_cpu else " (æœªæ£€æµ‹åˆ°GPU)"))
                # logger.info(f"ä½¿ç”¨CPUè¿›è¡ŒOCRè¯†åˆ« ({self.cpu_threads}çº¿ç¨‹)" + (" (å¼ºåˆ¶CPUæ¨¡å¼)" if self.force_cpu else " (æœªæ£€æµ‹åˆ°GPU)"))

            self.signals.progress.emit(10)
            print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–PaddleOCRæ¨¡å‹...")
            init_start = time.time()

            from infer_tu2 import OCR_process
            self.ocr_processor = OCR_process(self.config_dict)
            
            if not use_gpu:
                self.ocr_processor.enable_mkldnn = True
                self.ocr_processor.mkldnn_cache_capacity = 10
                self.ocr_processor.cpu_threads = self.cpu_threads
                self.ocr_processor._apply_config_to_models()
                print(f"âœ… å·²å¯ç”¨MKLDNNåŠ é€Ÿï¼Œçº¿ç¨‹æ•°: {self.cpu_threads}")
            
            init_time = time.time() - init_start
            print(f"âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼Œè€—æ—¶: {init_time:.2f}ç§’")
            # logger.info(f"æ¨¡å‹åˆå§‹åŒ–è€—æ—¶: {init_time:.2f}ç§’")
            self.signals.progress.emit(30)
            
            print(f"ğŸ“– æ­£åœ¨å¤„ç†æ–‡ä»¶: {self.image_path}")
            image_start = time.time()
            
            image = cv2.imread(self.image_path)
            if image is None:
                raise Exception(f"æ— æ³•è¯»å–å›¾åƒæ–‡ä»¶: {self.image_path}")
            
            image_time = time.time() - image_start
            img_height, img_width = image.shape[:2]
            img_size_mb = (image.nbytes / (1024 * 1024))
            
            print(f"ğŸ–¼ï¸ å›¾åƒè¯»å–æˆåŠŸï¼Œå°ºå¯¸: {image.shape}ï¼Œè€—æ—¶: {image_time:.2f}ç§’")
            # logger.info(f"å›¾åƒå°ºå¯¸: {img_width}x{img_height}ï¼Œå¤§å°: {img_size_mb:.2f}MBï¼Œè¯»å–è€—æ—¶: {image_time:.2f}ç§’")
            self.signals.progress.emit(50)
            
            print("ğŸ” å¼€å§‹OCRè¯†åˆ«...")
            ocr_start = time.time()

            # ç›´æ¥å¤„ç†æ•´å¼ å›¾åƒï¼Œæ— è®ºå¤§å°
            print("ğŸ“„ ä½¿ç”¨æ•´å›¾å•è¿›ç¨‹æ¨¡å¼å¤„ç†")
            img_list = [image]
            ocr_results = self._process_with_your_ocr(img_list)

            ocr_time = time.time() - ocr_start
            print(f"âœ… è¯†åˆ«å®Œæˆï¼Œå…±è¯†åˆ« {len(ocr_results)} ä¸ªæ–‡æœ¬ï¼ŒOCRå¤„ç†è€—æ—¶: {ocr_time:.2f}ç§’")
            # logger.info(f"OCRå¤„ç†å®Œæˆï¼Œè¯†åˆ«åˆ° {len(ocr_results)} ä¸ªæ–‡æœ¬ï¼Œå¤„ç†è€—æ—¶: {ocr_time:.2f}ç§’")
            self.signals.progress.emit(90)
            
            post_start = time.time()
            final_results = self._format_results_for_pyqt(ocr_results, image.shape)
            post_time = time.time() - post_start
            print(f"âœ… åå¤„ç†å®Œæˆï¼Œè€—æ—¶: {post_time:.2f}ç§’")
            
            total_time = time.time() - start_time
            end_datetime = datetime.now()
            
            print("\nâ±ï¸ æ—¶é—´ç»Ÿè®¡:")
            print(f"  æ¨¡å‹åˆå§‹åŒ–: {init_time:.2f}ç§’ ({(init_time/total_time*100):.1f}%)")
            print(f"  å›¾åƒè¯»å–: {image_time:.2f}ç§’ ({(image_time/total_time*100):.1f}%)")
            print(f"  OCRå¤„ç†: {ocr_time:.2f}ç§’ ({(ocr_time/total_time*100):.1f}%)")
            print(f"  åå¤„ç†: {post_time:.2f}ç§’ ({(post_time/total_time*100):.1f}%)")
            print(f"  æ€»è€—æ—¶: {total_time:.2f}ç§’")
            print(f"ğŸ“‹ OCRä»»åŠ¡ç»“æŸæ—¶é—´: {end_datetime.strftime('%Y-%m-%d %H:%M:%S')}")
            
            # åªè®°å½•å›¾åƒå¤§å°å’ŒOCRè¯†åˆ«æ—¶é—´
            logger.info(f"æ–‡ä»¶: {os.path.basename(self.image_path)}, å°ºå¯¸: {img_width}x{img_height}, å¤§å°: {img_size_mb:.2f}MB, OCRè¯†åˆ«æ—¶é—´: {ocr_time:.2f}ç§’")
            
            self.signals.progress.emit(100)
            self.signals.finished.emit(final_results)
            
        except Exception as e:
            error_msg = f"PaddleOCRè¯†åˆ«å¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            logger.error(f"æ–‡ä»¶: {os.path.basename(self.image_path)}, OCRè¯†åˆ«å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            self.signals.error.emit(error_msg)

    def _process_with_your_ocr(self, img_list):
        """ä½¿ç”¨æ‚¨çš„OCRå¤„ç†å™¨è¿›è¡Œè¯†åˆ« (ç¨³å®šåŸºå‡†ç‰ˆ)"""
        try:
            boxes = self.ocr_processor.ocr_det.predict(img_list)
            if not boxes:
                return []
            
            results = []
            i_boxes = boxes[0]

            if i_boxes is None or len(i_boxes) == 0:
                return []

            crop_img_list = []
            sortboxes = self.ocr_processor.sort_boxes(i_boxes)
            
            img_h, img_w = img_list[0].shape[:2]
            max_box_area = img_h * img_w * 0.3
            
            valid_boxes = []
            for box in sortboxes:
                try:
                    box_array = np.array(box)
                    x_min, y_min = np.min(box_array, axis=0)
                    x_max, y_max = np.max(box_array, axis=0)
                    box_area = (x_max - x_min) * (y_max - y_min)

                    if box_area > max_box_area:
                        print(f"âš ï¸ è¿‡æ»¤æ‰ä¸€ä¸ªå¼‚å¸¸å¤§çš„æ£€æµ‹æ¡†ï¼Œé¢ç§¯: {box_area:.0f} > é˜ˆå€¼: {max_box_area:.0f}")
                        continue
                except Exception:
                    continue

                bbox_info = self.ocr_processor.get_bbox_info(box)
                crop_img = self.ocr_processor.rectify_crop(img_list[0], bbox_info)
                crop_img_list.append(crop_img)
                valid_boxes.append(box)
            
            if not crop_img_list:
                return []
            
            info_stream = list(self.ocr_processor.ocr_rec.predict(crop_img_list))
            
            for idx, info in enumerate(info_stream):
                if info and '\t' in info:
                    ocr_str = info.split("\t")
                    text = ocr_str[0]
                    confidence = float(ocr_str[1]) if len(ocr_str) > 1 else 0.9
                    
                    if '#' not in text and text.strip():
                        results.append({
                            'text': text,
                            'confidence': confidence,
                            'bbox': valid_boxes[idx].tolist() if idx < len(valid_boxes) else []
                        })
            
            return results
            
        except Exception as e:
            print(f"âŒ OCRå¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return []

    def _format_results_for_pyqt(self, ocr_results: List[Dict], image_shape: Tuple[int, int, int]) -> List[Dict]:
        """å°†OCRç»“æœæ ¼å¼åŒ–ä¸ºPyQtåº”ç”¨ç¨‹åºæ‰€éœ€çš„æ ¼å¼"""
        formatted_results = []
        total_results = len(ocr_results)
        masked_count = 0
        
        for result in ocr_results:
            bbox = result.get('bbox')
            text = result.get('text', '')
            
            if not bbox or len(bbox) < 4:
                continue

            bbox_array = np.array(bbox)
            center_x = int(np.mean(bbox_array[:, 0]))
            center_y = int(np.mean(bbox_array[:, 1]))
            bbox_width = int(np.max(bbox_array[:, 0]) - np.min(bbox_array[:, 0]))
            bbox_height = int(np.max(bbox_array[:, 1]) - np.min(bbox_array[:, 1]))
            
            if self.masked_regions and self._is_bbox_in_masked_region(bbox):
                masked_count += 1
                continue
                
            clean_text = self._clean_text(text)
            if not clean_text:
                continue
            
            text_type = self._classify_mechanical_text(clean_text)
            
            formatted_results.append({
                'text': clean_text,
                'confidence': result.get('confidence', 0.0),
                'center_x': center_x,
                'center_y': center_y,
                'bbox_width': bbox_width,
                'bbox_height': bbox_height,
                'bbox': bbox,
                'type': text_type,
                'original_text': text
            })
        
        if masked_count > 0:
            print(f"ğŸš« å·²æ ¹æ®å±è”½åŒºåŸŸè¿‡æ»¤æ‰ {masked_count}/{total_results} ä¸ªç»“æœã€‚")
            
        return formatted_results

    def _is_bbox_in_masked_region(self, bbox: List[Tuple[int, int]]) -> bool:
        """æ£€æŸ¥ç»™å®šçš„è¾¹ç•Œæ¡†æ˜¯å¦å®Œå…¨ä½äºä»»ä½•ä¸€ä¸ªå±è”½åŒºåŸŸå†…"""
        bbox_center = np.mean(np.array(bbox), axis=0)
        
        for region in self.masked_regions:
            if (region['x'] <= bbox_center[0] <= region['x'] + region['width'] and
                region['y'] <= bbox_center[1] <= region['y'] + region['height']):
                return True
        return False

    def _clean_text(self, text: str) -> str:
        """æ¸…ç†OCRè¯†åˆ«å‡ºçš„åŸå§‹æ–‡æœ¬"""
        return text.strip()
    
    def _classify_mechanical_text(self, text: str) -> str:
        """æ ¹æ®æ–‡æœ¬å†…å®¹å¯¹æœºæ¢°å›¾çº¸ä¸­çš„æ–‡æœ¬è¿›è¡Œåˆ†ç±»"""
        text = text.upper().replace(" ", "")
        
        if re.match(r'^M\d+(\.\d+)?(X\d+(\.\d+)?)?', text):
            return "èºçº¹è§„æ ¼"
        if re.match(r'^(Î¦|âˆ…|Ã˜)\d+', text):
            return "ç›´å¾„æ ‡æ³¨"
        if re.search(r'\d', text) and not re.search(r'[A-Z]{2,}', text):
            return "å°ºå¯¸æ ‡æ³¨"
        if re.match(r'^[A-Z0-9\s-]+$', text) and len(re.sub(r'[^A-Z]', '', text)) > 1:
            return "ææ–™æ ‡è®°"
        
        return 'annotation'
