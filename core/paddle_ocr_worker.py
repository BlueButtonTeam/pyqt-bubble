#!/usr/bin/env python3
"""
PaddleOCRè¯†åˆ«å·¥ä½œçº¿ç¨‹æ¨¡å— - ä½¿ç”¨æ‚¨è®­ç»ƒçš„ä¸“ç”¨æ¨¡å‹
é’ˆå¯¹æœºæ¢°å›¾çº¸è¿›è¡Œæ·±åº¦ä¼˜åŒ–çš„OCRè¯†åˆ«ç³»ç»Ÿ
"""

import sys
import os
import cv2
import numpy as np
import logging
import re
from PySide6.QtCore import QObject, QRunnable, Signal
from typing import List, Dict, Tuple, Optional, Any

# æ·»åŠ PaddleOCRè·¯å¾„ - ä½¿ç”¨æœ¬åœ°æ–‡ä»¶
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)  # pyqt-bubble2ç›®å½•
sys.path.insert(0, parent_dir)  # æ·»åŠ pyqt-bubble2åˆ°è·¯å¾„

# è®¾ç½®ä¸infer_tu2.pyç›¸åŒçš„GPUç¯å¢ƒå˜é‡
os.environ["FLAGS_allocator_strategy"] = 'auto_growth'
os.environ["CUDA_VISIBLE_DEVICES"] = "0"

# å¯¼å…¥PaddleOCRç›¸å…³æ¨¡å—
try:
    # å¯¼å…¥PaddleOCRæ ¸å¿ƒæ¨¡å—
    from ppocr.data import create_operators, transform
    from ppocr.modeling.architectures import build_model
    from ppocr.postprocess import build_post_process
    from ppocr.utils.save_load import load_model
    from ppocr.utils.utility import get_image_file_list
    import paddle
    import yaml
    import copy
    import numpy as np
    import cv2
    PADDLE_AVAILABLE = True
    
    # æ£€æµ‹GPUæ”¯æŒ
    HAS_GPU_SUPPORT = False
    try:
        if paddle.is_compiled_with_cuda():
            # æ£€æŸ¥GPUæ˜¯å¦å®é™…å¯ç”¨
            gpu_count = paddle.device.cuda.device_count()
            HAS_GPU_SUPPORT = gpu_count > 0
            if HAS_GPU_SUPPORT:
                print(f"âœ… æ£€æµ‹åˆ°{gpu_count}ä¸ªå¯ç”¨GPU")
            else:
                print("âš ï¸ å·²ç¼–è¯‘CUDAæ”¯æŒï¼Œä½†æœªæ£€æµ‹åˆ°å¯ç”¨GPUè®¾å¤‡")
        else:
            print("âš ï¸ PaddlePaddleæœªä½¿ç”¨CUDAç¼–è¯‘")
    except Exception as e:
        print(f"âš ï¸ æ£€æµ‹GPUæ”¯æŒæ—¶å‡ºé”™: {e}")
        HAS_GPU_SUPPORT = False
    
    print("âœ… PaddleOCRæ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    logging.warning(f"PaddleOCR not available: {e}")
    PADDLE_AVAILABLE = False
    HAS_GPU_SUPPORT = False
    print(f"âŒ PaddleOCRæ¨¡å—å¯¼å…¥å¤±è´¥: {e}")


class PaddleOCRWorkerSignals(QObject):
    """PaddleOCRå·¥ä½œçº¿ç¨‹ä¿¡å·"""
    finished = Signal(list)  # OCRå®Œæˆä¿¡å·ï¼Œä¼ é€’è¯†åˆ«ç»“æœåˆ—è¡¨
    progress = Signal(int)   # è¿›åº¦ä¿¡å·
    error = Signal(str)      # é”™è¯¯ä¿¡å·


class PaddleOCRWorker(QRunnable):
    """PaddleOCRè¯†åˆ«å·¥ä½œçº¿ç¨‹ - ä½¿ç”¨æ‚¨è®­ç»ƒçš„ä¸“ç”¨æ¨¡å‹"""
    
    def __init__(self, image_path: str, languages: list = ['ch_sim', 'en'], masked_regions: list = None, force_cpu: bool = False, cpu_threads: int = 8):
        super().__init__()
        self.image_path = image_path
        self.languages = languages  # ä¿æŒå…¼å®¹æ€§ï¼Œä½†PaddleOCRä¸ä½¿ç”¨è¿™ä¸ªå‚æ•°
        self.masked_regions = masked_regions or []
        self.signals = PaddleOCRWorkerSignals()
        self.force_cpu = force_cpu  # æ˜¯å¦å¼ºåˆ¶ä½¿ç”¨CPU
        self.cpu_threads = cpu_threads  # CPUçº¿ç¨‹æ•°
        
        # é…ç½®å­—å…¸ - ä½¿ç”¨æœ¬åœ°æ–‡ä»¶
        self.config_dict = {
            "ocr_det_config": os.path.join(parent_dir, "model", "det_best_model", "config.yml"),
            "ocr_rec_config": os.path.join(parent_dir, "configs", "rec", "PP-OCRv4", "ch_PP-OCRv4_rec_hgnet.yml")
        }
        
        # OCRå¤„ç†å™¨
        self.ocr_processor = None
    
    def run(self):
        """æ‰§è¡ŒPaddleOCRè¯†åˆ« - ä½¿ç”¨ä¸infer_tu2.pyç›¸åŒçš„GPUé…ç½®"""
        if not PADDLE_AVAILABLE:
            self.signals.error.emit("PaddleOCRåŠŸèƒ½æœªå¯ç”¨ï¼Œè¯·å®‰è£…PaddlePaddle")
            return

        try:
            # è®°å½•å¼€å§‹æ—¶é—´
            import time
            from datetime import datetime
            start_time = time.time()
            start_datetime = datetime.now()
            print(f"\nğŸ“‹ OCRä»»åŠ¡å¼€å§‹æ—¶é—´: {start_datetime.strftime('%Y-%m-%d %H:%M:%S')}")
            print(f"ğŸ“„ å¤„ç†æ–‡ä»¶: {os.path.basename(self.image_path)}")

            # è®¾ç½®ä¼˜åŒ–ç¯å¢ƒå˜é‡
            os.environ["OMP_NUM_THREADS"] = str(self.cpu_threads)  # ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„OpenMPçº¿ç¨‹æ•°
            os.environ["KMP_AFFINITY"] = "granularity=fine,compact,1,0"  # çº¿ç¨‹äº²å’Œæ€§

            # ç¡®å®šä½¿ç”¨è®¾å¤‡
            use_gpu = HAS_GPU_SUPPORT and not self.force_cpu
            if use_gpu:
                print("ğŸš€ ä½¿ç”¨GPUè¿›è¡ŒPaddleOCRè¯†åˆ«")
            else:
                print(f"ğŸš€ ä½¿ç”¨CPUè¿›è¡ŒPaddleOCRè¯†åˆ« ({self.cpu_threads}çº¿ç¨‹)" + (" (å¼ºåˆ¶CPUæ¨¡å¼)" if self.force_cpu else " (æœªæ£€æµ‹åˆ°GPU)"))

            # åˆå§‹åŒ–OCRå¤„ç†å™¨
            self.signals.progress.emit(10)
            print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–PaddleOCRæ¨¡å‹...")
            init_start = time.time()

            # å¯¼å…¥æ‚¨çš„OCRå¤„ç†ç±» - ä»æœ¬åœ°æ–‡ä»¶
            from infer_tu2 import OCR_process

            self.ocr_processor = OCR_process(self.config_dict)
            
            # é…ç½®CPUä¼˜åŒ– (å½“ä½¿ç”¨CPUæ—¶å¯ç”¨MKLDNN)
            if not use_gpu:
                self.ocr_processor.enable_mkldnn = True
                self.ocr_processor.mkldnn_cache_capacity = 10
                self.ocr_processor.cpu_threads = self.cpu_threads  # ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„çº¿ç¨‹æ•°
                # é‡æ–°åº”ç”¨é…ç½®
                self.ocr_processor._apply_config_to_models()
                print(f"âœ… å·²å¯ç”¨MKLDNNåŠ é€Ÿï¼Œçº¿ç¨‹æ•°: {self.cpu_threads}")
            
            init_time = time.time() - init_start
            print(f"âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼Œè€—æ—¶: {init_time:.2f}ç§’")
            self.signals.progress.emit(30)
            
            # è¯»å–å›¾åƒ
            print(f"ğŸ“– æ­£åœ¨å¤„ç†æ–‡ä»¶: {self.image_path}")
            image_start = time.time()
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(self.image_path):
                raise Exception(f"æ–‡ä»¶ä¸å­˜åœ¨: {self.image_path}")
                
            # æ£€æŸ¥è·¯å¾„ä¸­æ˜¯å¦åŒ…å«éASCIIå­—ç¬¦
            has_non_ascii = any(ord(c) > 127 for c in self.image_path)
            if has_non_ascii:
                print(f"âš ï¸ è­¦å‘Š: æ–‡ä»¶è·¯å¾„åŒ…å«éASCIIå­—ç¬¦ï¼Œå¯èƒ½å¯¼è‡´è¯»å–é—®é¢˜: {self.image_path}")
                
                # å°è¯•åˆ›å»ºç¬¦å·é“¾æ¥åˆ°ä¸´æ—¶ç›®å½•çš„ASCIIæ–‡ä»¶å
                try:
                    import tempfile
                    import uuid
                    import shutil
                    temp_dir = tempfile.gettempdir()
                    temp_filename = f"ocr_temp_{uuid.uuid4().hex[:8]}{os.path.splitext(self.image_path)[1]}"
                    temp_path = os.path.join(temp_dir, temp_filename)
                    
                    # å¤åˆ¶æ–‡ä»¶åˆ°ä¸´æ—¶è·¯å¾„
                    print(f"âš™ï¸ å¤åˆ¶æ–‡ä»¶åˆ°ä¸´æ—¶ASCIIè·¯å¾„: {temp_path}")
                    shutil.copy2(self.image_path, temp_path)
                    
                    # ä½¿ç”¨æ–°çš„ä¸´æ—¶è·¯å¾„
                    self.image_path = temp_path
                    print(f"âœ… æˆåŠŸåˆ›å»ºä¸´æ—¶æ–‡ä»¶: {self.image_path}")
                except Exception as e:
                    print(f"âš ï¸ åˆ›å»ºä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}, ç»§ç»­ä½¿ç”¨åŸè·¯å¾„")
            
            # ä½¿ç”¨OpenCVè¯»å–å›¾åƒ
            image = cv2.imread(self.image_path)
            if image is None:
                # å°è¯•ä½¿ç”¨å¤‡ç”¨æ–¹æ³•è¯»å–
                try:
                    print("âš ï¸ OpenCVæ— æ³•è¯»å–å›¾åƒï¼Œå°è¯•ä½¿ç”¨PIL...")
                    from PIL import Image as PILImage
                    pil_img = PILImage.open(self.image_path)
                    # å°†PILå›¾åƒè½¬æ¢ä¸ºOpenCVæ ¼å¼
                    if pil_img.mode == 'RGBA':
                        pil_img = pil_img.convert('RGB')
                    image = np.array(pil_img)
                    # è½¬æ¢RGBåˆ°BGR (OpenCVä½¿ç”¨BGR)
                    image = image[:, :, ::-1].copy()
                    print("âœ… ä½¿ç”¨PILæˆåŠŸè¯»å–å›¾åƒ")
                except Exception as pil_error:
                    raise Exception(f"æ— æ³•è¯»å–å›¾åƒæ–‡ä»¶: {self.image_path}\nOpenCVé”™è¯¯: æ— æ³•è§£ç å›¾åƒ\nPILé”™è¯¯: {str(pil_error)}")
            
            image_time = time.time() - image_start
            print(f"ğŸ–¼ï¸ å›¾åƒè¯»å–æˆåŠŸï¼Œå°ºå¯¸: {image.shape}ï¼Œè€—æ—¶: {image_time:.2f}ç§’")
            self.signals.progress.emit(50)
            
            # ä½¿ç”¨æ‚¨çš„OCRå¤„ç†å™¨è¿›è¡Œè¯†åˆ«
            print("ğŸ” å¼€å§‹OCRè¯†åˆ«...")
            ocr_start = time.time()
            img_list = [image]
            
            # è°ƒç”¨æ‚¨çš„process_imgsæ–¹æ³•
            ocr_results = self._process_with_your_ocr(img_list)
            
            ocr_time = time.time() - ocr_start
            print(f"âœ… è¯†åˆ«å®Œæˆï¼Œå…±è¯†åˆ« {len(ocr_results)} ä¸ªæ–‡æœ¬ï¼ŒOCRå¤„ç†è€—æ—¶: {ocr_time:.2f}ç§’")
            self.signals.progress.emit(90)
            
            # å¤„ç†ç»“æœä¸ºPyQtéœ€è¦çš„æ ¼å¼
            post_start = time.time()
            final_results = self._format_results_for_pyqt(ocr_results, image.shape)
            post_time = time.time() - post_start
            print(f"âœ… åå¤„ç†å®Œæˆï¼Œè€—æ—¶: {post_time:.2f}ç§’")
            
            # è®¡ç®—æ€»è€—æ—¶
            total_time = time.time() - start_time
            end_datetime = datetime.now()
            
            # æ˜¾ç¤ºè¯¦ç»†çš„æ—¶é—´ç»Ÿè®¡
            print("\nâ±ï¸ æ—¶é—´ç»Ÿè®¡:")
            print(f"  æ¨¡å‹åˆå§‹åŒ–: {init_time:.2f}ç§’ ({(init_time/total_time*100):.1f}%)")
            print(f"  å›¾åƒè¯»å–: {image_time:.2f}ç§’ ({(image_time/total_time*100):.1f}%)")
            print(f"  OCRå¤„ç†: {ocr_time:.2f}ç§’ ({(ocr_time/total_time*100):.1f}%)")
            print(f"  åå¤„ç†: {post_time:.2f}ç§’ ({(post_time/total_time*100):.1f}%)")
            print(f"  æ€»è€—æ—¶: {total_time:.2f}ç§’")
            print(f"ğŸ“‹ OCRä»»åŠ¡ç»“æŸæ—¶é—´: {end_datetime.strftime('%Y-%m-%d %H:%M:%S')}")
            
            self.signals.progress.emit(100)
            self.signals.finished.emit(final_results)
            
        except Exception as e:
            error_msg = f"PaddleOCRè¯†åˆ«å¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            import traceback
            traceback.print_exc()
            self.signals.error.emit(error_msg)
    
    def _process_with_your_ocr(self, img_list):
        """ä½¿ç”¨æ‚¨çš„OCRå¤„ç†å™¨è¿›è¡Œè¯†åˆ«"""
        try:
            # è·å–æ£€æµ‹æ¡†
            boxes = self.ocr_processor.ocr_det.predict(img_list)
            if len(boxes) == 0:
                return []
            
            results = []
            for i, i_boxes in enumerate(boxes):
                crop_img_list = []
                sortboxes = self.ocr_processor.sort_boxes(i_boxes)
                
                for box in sortboxes:
                    bbox_info = self.ocr_processor.get_bbox_info(box)
                    crop_img = self.ocr_processor.rectify_crop(img_list[i], bbox_info)
                    crop_img_list.append(crop_img)
                
                # è·å–è¯†åˆ«ç»“æœ
                info_stream = self.ocr_processor.ocr_rec.predict(crop_img_list)
                
                for idx, info in enumerate(info_stream):
                    if info and '\t' in info:
                        ocr_str = info.split("\t")
                        text = ocr_str[0]
                        confidence = float(ocr_str[1]) if len(ocr_str) > 1 else 0.9
                        
                        # è¿‡æ»¤æ‰åŒ…å«#çš„æ–‡æœ¬
                        if '#' not in text and text.strip():
                            results.append({
                                'text': text,
                                'confidence': confidence,
                                'bbox': sortboxes[idx].tolist() if idx < len(sortboxes) else []
                            })
            
            return results
            
        except Exception as e:
            print(f"âŒ OCRå¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def _format_results_for_pyqt(self, ocr_results, image_shape):
        """å°†OCRç»“æœæ ¼å¼åŒ–ä¸ºPyQtéœ€è¦çš„æ ¼å¼"""
        formatted_results = []
        
        for result in ocr_results:
            bbox = result['bbox']
            text = result['text']
            confidence = result['confidence']
            
            if not bbox or len(bbox) < 4:
                continue
            
            # æ£€æŸ¥bboxæ˜¯å¦åœ¨å±è”½åŒºåŸŸå†…
            if self._is_bbox_in_masked_region(bbox):
                continue
            
            # è®¡ç®—ä¸­å¿ƒç‚¹å’Œè¾¹ç•Œæ¡†å°ºå¯¸
            bbox_array = np.array(bbox)
            center_x = int(np.mean(bbox_array[:, 0]))
            center_y = int(np.mean(bbox_array[:, 1]))
            
            # æ¸…ç†æ–‡æœ¬
            cleaned_text = self._clean_text(text)
            if not cleaned_text:
                continue
                
            # è®¡ç®—ä¿¡æ¯ç±»å‹ï¼ˆå·¥ç¨‹å›¾çº¸æ–‡å­—åˆ†ç±»ï¼‰
            info_type = self._classify_mechanical_text(cleaned_text)
            
            # åˆ›å»ºæ ¼å¼åŒ–ç»“æœ
            formatted_results.append({
                'text': cleaned_text,
                'confidence': confidence,
                'bbox': bbox,
                'center': (center_x, center_y),
                'type': info_type,
                'color': None  # é¢œè‰²ç”±UIå¤„ç†
            })
        
        return formatted_results
    
    def _is_bbox_in_masked_region(self, bbox):
        """æ£€æŸ¥bboxæ˜¯å¦åœ¨å±è”½åŒºåŸŸå†…"""
        if not self.masked_regions:
            return False
            
        # è®¡ç®—bboxçš„ä¸­å¿ƒç‚¹
        bbox_array = np.array(bbox)
        center_x = np.mean(bbox_array[:, 0])
        center_y = np.mean(bbox_array[:, 1])
        
        # æ£€æŸ¥æ˜¯å¦åœ¨ä»»ä½•å±è”½åŒºåŸŸå†…
        for region in self.masked_regions:
            # æ”¯æŒä¸¤ç§æ ¼å¼çš„å±è”½åŒºåŸŸ
            if isinstance(region, dict):  # å­—å…¸æ ¼å¼ {'x': x, 'y': y, 'width': w, 'height': h}
                x, y = region.get('x', 0), region.get('y', 0)
                width, height = region.get('width', 0), region.get('height', 0)
                
                if (x <= center_x <= x + width) and (y <= center_y <= y + height):
                    return True
            else:  # QRectFæ ¼å¼
                try:
                    if region.contains(center_x, center_y):
                        return True
                except AttributeError:
                    pass  # ä¸æ˜¯QRectFå¯¹è±¡ï¼Œè·³è¿‡
                    
        return False
    
    def _clean_text(self, text):
        """æ¸…ç†è¯†åˆ«çš„æ–‡æœ¬"""
        # ç§»é™¤å¤šä½™ç©ºæ ¼
        text = re.sub(r'\s+', ' ', text.strip())
        
        # ä¿®æ­£å¸¸è§çš„OCRé”™è¯¯
        corrections = {
            'Î¦': 'Î¦',  # ç›´å¾„ç¬¦å·
            'âˆ…': 'Î¦',
            'Ã¸': 'Î¦',
            'M': 'M',   # èºçº¹æ ‡è®°
            'Ã—': 'Ã—',   # ä¹˜å·
            'Â°': 'Â°',   # åº¦æ•°ç¬¦å·
        }
        
        for wrong, correct in corrections.items():
            text = text.replace(wrong, correct)
        
        return text
    
    def _classify_mechanical_text(self, text):
        """åˆ†ç±»æœºæ¢°å›¾çº¸æ–‡æœ¬ç±»å‹"""
        # èºçº¹è§„æ ¼
        if re.match(r'M\d+', text, re.IGNORECASE):
            return 'thread_spec'
        
        # ç›´å¾„æ ‡æ³¨
        if 'Î¦' in text or 'âˆ…' in text or 'Ã¸' in text:
            return 'diameter'
        
        # å°ºå¯¸æ ‡æ³¨
        if re.search(r'\d+\.?\d*\s*[Ã—x]\s*\d+\.?\d*', text):
            return 'dimension'
        
        # è§’åº¦æ ‡æ³¨
        if 'Â°' in text and any(c.isdigit() for c in text):
            return 'angle'
        
        # æ•°å€¼
        if re.match(r'^\d+\.?\d*$', text):
            return 'number'
        
        # ææ–™æ ‡è®°
        material_keywords = ['é’¢', 'é“', 'é“œ', 'é“', 'ä¸é”ˆé’¢', 'steel', 'iron', 'copper', 'aluminum']
        if any(keyword.lower() in text.lower() for keyword in material_keywords):
            return 'material'
        
        # è¡¨é¢å¤„ç†
        surface_keywords = ['é•€é”Œ', 'å‘é»‘', 'é˜³æ', 'å–·æ¶‚', 'zinc', 'black', 'anodize', 'coating']
        if any(keyword.lower() in text.lower() for keyword in surface_keywords):
            return 'surface_treatment'
        
        # é»˜è®¤ä¸ºæ ‡æ³¨æ–‡æœ¬
        return 'annotation'
