#!/usr/bin/env python3
"""
OCRè¯†åˆ«å·¥ä½œçº¿ç¨‹æ¨¡å— - å¢å¼ºç‰ˆ
é’ˆå¯¹æœºæ¢°å›¾çº¸è¿›è¡Œæ·±åº¦ä¼˜åŒ–çš„OCRè¯†åˆ«ç³»ç»Ÿ
"""

import re
from PySide6.QtCore import QObject, QRunnable, Signal
from utils.dependencies import HAS_OCR_SUPPORT

if HAS_OCR_SUPPORT:
    import cv2
    import numpy as np
    import torch
    import easyocr
    import fitz


class OCRWorkerSignals(QObject):
    """OCRå·¥ä½œçº¿ç¨‹ä¿¡å·"""
    finished = Signal(list)  # OCRå®Œæˆä¿¡å·ï¼Œä¼ é€’è¯†åˆ«ç»“æœåˆ—è¡¨
    progress = Signal(int)   # è¿›åº¦ä¿¡å·
    error = Signal(str)      # é”™è¯¯ä¿¡å·


class OCRWorker(QRunnable):
    """OCRè¯†åˆ«å·¥ä½œçº¿ç¨‹ - å¢å¼ºç‰ˆ"""
    
    def __init__(self, image_path: str, languages: list = ['ch_sim', 'en'], masked_regions: list = None):
        super().__init__()
        self.image_path = image_path
        self.languages = languages
        self.masked_regions = masked_regions or []  # å±è”½åŒºåŸŸåˆ—è¡¨
        self.signals = OCRWorkerSignals()
        self._reader = None
        
    def run(self):
        """æ‰§è¡ŒOCRè¯†åˆ« - å¤šç­–ç•¥å¢å¼ºç‰ˆ"""
        if not HAS_OCR_SUPPORT:
            self.signals.error.emit("OCRåŠŸèƒ½æœªå¯ç”¨ï¼Œè¯·å®‰è£…å®Œæ•´ä¾èµ–åŒ…")
            return
            
        try:
            # åˆå§‹åŒ–EasyOCRï¼ˆä¼˜åŒ–ç‰ˆï¼‰
            if not self._reader:
                self.signals.progress.emit(5)
                print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–å¢å¼ºç‰ˆEasyOCR...")
                
                # é…ç½®EasyOCRå‚æ•°ä»¥æé«˜ç²¾åº¦
                gpu_available = torch.cuda.is_available()
                print(f"ğŸ–¥ï¸  GPUå¯ç”¨: {gpu_available}")
                
                self._reader = easyocr.Reader(
                    self.languages, 
                    gpu=gpu_available,
                    verbose=False,          # å‡å°‘è¾“å‡º
                    quantize=True,          # å¯ç”¨é‡åŒ–ä»¥æé«˜æ€§èƒ½
                    download_enabled=True   # å…è®¸ä¸‹è½½æ¨¡å‹
                )
                print("âœ… å¢å¼ºç‰ˆEasyOCRåˆå§‹åŒ–å®Œæˆ")
            
            self.signals.progress.emit(15)
            
            # è¯»å–å¹¶å¤„ç†å›¾åƒ
            print(f"ğŸ“– æ­£åœ¨å¤„ç†æ–‡ä»¶: {self.image_path}")
            
            # è·å–å›¾åƒæ•°æ®
            if self.image_path.lower().endswith('.pdf'):
                # PDFæ–‡ä»¶ï¼šå…ˆè½¬æ¢ä¸ºå›¾åƒ
                image = self._extract_image_from_pdf_with_same_scale()
                if image is None:
                    raise Exception("æ— æ³•ä»PDFæå–å›¾åƒ")
                print(f"ğŸ“„ PDFè½¬æ¢ä¸ºå›¾åƒæˆåŠŸï¼Œå°ºå¯¸: {image.shape}")
            else:
                # å›¾åƒæ–‡ä»¶ï¼šç›´æ¥è¯»å–
                image = cv2.imread(self.image_path)
                if image is None:
                    raise Exception(f"æ— æ³•è¯»å–å›¾åƒæ–‡ä»¶: {self.image_path}")
                print(f"ğŸ–¼ï¸ å›¾åƒè¯»å–æˆåŠŸï¼Œå°ºå¯¸: {image.shape}")
            
            self.signals.progress.emit(25)
            
            print("ğŸ” å¼€å§‹OCRè¯†åˆ«...")
            
            # ä¸»è¯†åˆ«ç­–ç•¥ï¼šä½¿ç”¨åŸå§‹å›¾åƒ
            all_results = []
            try:
                print("  ğŸ¯ ä½¿ç”¨ä¸»è¯†åˆ«ç­–ç•¥...")
                results = self._reader.readtext(
                    image,
                    detail=1,
                    width_ths=0.7,      # æ–‡æœ¬å®½åº¦é˜ˆå€¼
                    height_ths=0.7,     # æ–‡æœ¬é«˜åº¦é˜ˆå€¼
                    paragraph=False,    # ä¸åˆå¹¶æ®µè½
                    min_size=8,         # æœ€å°æ–‡æœ¬å°ºå¯¸
                    text_threshold=0.6, # æ–‡æœ¬ç½®ä¿¡åº¦é˜ˆå€¼
                    low_text=0.3,       # ä½æ–‡æœ¬é˜ˆå€¼
                    link_threshold=0.3, # è¿æ¥é˜ˆå€¼
                    canvas_size=2560,   # ç”»å¸ƒå¤§å°
                    mag_ratio=1.8       # æ”¾å¤§æ¯”ä¾‹
                )
                
                print(f"  ğŸ“ ä¸»è¯†åˆ«æ–¹æ³•è¯†åˆ«åˆ° {len(results)} ä¸ªæ–‡æœ¬")
                
                # ä¸ºç»“æœæ·»åŠ æ–¹æ³•æ ‡è¯†
                for result in results:
                    result_list = list(result)
                    result_list.append("primary_method")
                    all_results.append(result_list)
                    
            except Exception as e:
                print(f"  âš ï¸ ä¸»è¯†åˆ«æ–¹æ³•å¤±è´¥: {e}")
            
            self.signals.progress.emit(75)
            
            # å¦‚æœä¸»æ–¹æ³•ç»“æœå¤ªå°‘ï¼Œå°è¯•å¤‡ç”¨æ–¹æ³•
            if len(all_results) < 5:
                print("ğŸ”„ ç»“æœè¾ƒå°‘ï¼Œå°è¯•å¤‡ç”¨è¯†åˆ«ç­–ç•¥...")
                try:
                    # ç®€å•çš„å›¾åƒå¢å¼º
                    processed_images = self._simple_preprocessing(image)
                    
                    for i, processed_img in enumerate(processed_images[:1]):  # åªä½¿ç”¨ç¬¬ä¸€ç§å¤‡ç”¨æ–¹æ³•ï¼Œé¿å…å†…å­˜é—®é¢˜
                        try:
                            backup_results = self._reader.readtext(
                                processed_img,
                                detail=1,
                                width_ths=0.7,
                                height_ths=0.7,
                                paragraph=False,
                                min_size=8,
                                text_threshold=0.5,  # ç¨å¾®é™ä½é˜ˆå€¼
                                low_text=0.3,
                                link_threshold=0.3,
                                canvas_size=1280,    # å‡å°ç”»å¸ƒå¤§å°é¿å…å†…å­˜é—®é¢˜
                                mag_ratio=1.5        # å‡å°æ”¾å¤§æ¯”ä¾‹
                            )
                            
                            for result in backup_results:
                                result_list = list(result)
                                result_list.append(f"backup_method_{i}")
                                all_results.append(result_list)
                            
                            print(f"  ğŸ“ å¤‡ç”¨æ–¹æ³•{i+1}è¯†åˆ«åˆ° {len(backup_results)} ä¸ªæ–‡æœ¬")
                            break  # æˆåŠŸåé€€å‡ºå¾ªç¯ï¼Œé¿å…è¿‡åº¦å¤„ç†
                            
                        except Exception as e:
                            print(f"  âš ï¸ å¤‡ç”¨æ–¹æ³•{i+1}å¤±è´¥: {e}")
                            continue
                        
                except Exception as e:
                    print(f"  âš ï¸ å¤‡ç”¨è¯†åˆ«ç­–ç•¥å¤±è´¥: {e}")
            
            # å¤„ç†è¯†åˆ«ç»“æœ
            if all_results:
                print("ğŸ”§ æ­£åœ¨å¤„ç†è¯†åˆ«ç»“æœ...")
                processed_results = self._process_ocr_results(all_results, image.shape)
                
                self.signals.progress.emit(90)
                
                # æœ€ç»ˆç»“æœç­›é€‰å’Œæ’åº
                print("ğŸ¯ æ­£åœ¨è¿›è¡Œæœ€ç»ˆç»“æœç­›é€‰...")
                final_results = self._final_result_filtering(processed_results)
                
                print(f"âœ… OCRè¯†åˆ«å®Œæˆï¼æœ€ç»ˆè¯†åˆ«åˆ° {len(final_results)} ä¸ªæœ‰æ•ˆæ–‡æœ¬")
            else:
                print("âš ï¸ æ²¡æœ‰è¯†åˆ«åˆ°ä»»ä½•æ–‡æœ¬")
                final_results = []
            
            self.signals.progress.emit(100)
            self.signals.finished.emit(final_results)
            
        except Exception as e:
            error_msg = f"OCRè¯†åˆ«å¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            self.signals.error.emit(error_msg)
    
    def _extract_image_from_pdf_with_same_scale(self):
        """ä»PDFä¸­æå–å›¾åƒ - ä½¿ç”¨ä¸æ˜¾ç¤ºç›¸åŒçš„ç¼©æ”¾æ¯”ä¾‹"""
        try:
            # é‡è¦ï¼šè¿™ä¸ªæ–¹æ³•ç°åœ¨åº”è¯¥å°½é‡ä¸FileLoader.load_pdfä¿æŒä¸€è‡´çš„ç¼©æ”¾
            doc = fitz.open(self.image_path)
            page = doc[0]  # è·å–ç¬¬ä¸€é¡µ
            
            # ä½¿ç”¨æ ‡å‡†4å€ç¼©æ”¾ï¼ˆä¸é»˜è®¤PDFåŠ è½½ä¸€è‡´ï¼‰
            mat = fitz.Matrix(4.0, 4.0)
            pix = page.get_pixmap(matrix=mat, alpha=False)
            img_data = pix.tobytes("png")
            
            # è½¬æ¢ä¸ºOpenCVæ ¼å¼
            nparr = np.frombuffer(img_data, np.uint8)
            image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
            doc.close()
            return image
        except Exception as e:
            print(f"PDFå›¾åƒæå–å¤±è´¥: {e}")
            return None
    
    def _simple_preprocessing(self, image):
        """ç®€å•çš„å›¾åƒé¢„å¤„ç† - å†…å­˜ä¼˜åŒ–ç‰ˆ"""
        # è½¬æ¢ä¸ºç°åº¦å›¾
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image.copy()
        
        # åªä½¿ç”¨æœ€æœ‰æ•ˆçš„ä¸€ç§é¢„å¤„ç†æ–¹æ³•ï¼Œå‡å°‘å†…å­˜å ç”¨
        processed_images = []
        
        try:
            # æ–¹æ³•ï¼šåŸºç¡€CLAHE + è‡ªé€‚åº”é˜ˆå€¼ï¼ˆç»éªŒè¯æœ€æœ‰æ•ˆä¸”å†…å­˜å‹å¥½ï¼‰
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
            enhanced = clahe.apply(gray)
            
            # ä½¿ç”¨è½»é‡çº§çš„åŒè¾¹æ»¤æ³¢
            denoised = cv2.bilateralFilter(enhanced, 5, 50, 50)  # å‡å°å‚æ•°é™ä½å†…å­˜ä½¿ç”¨
            
            # è‡ªé€‚åº”é˜ˆå€¼
            adaptive_thresh = cv2.adaptiveThreshold(
                denoised, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                cv2.THRESH_BINARY, 11, 2
            )
            processed_images.append(adaptive_thresh)
            
        except Exception as e:
            print(f"  âš ï¸ å›¾åƒé¢„å¤„ç†å¤±è´¥: {e}")
            # å¦‚æœé¢„å¤„ç†å¤±è´¥ï¼Œè¿”å›åŸå§‹ç°åº¦å›¾
            processed_images.append(gray)
        
        return processed_images
    
    def _process_ocr_results(self, results, image_shape):
        """å¤„ç†OCRè¯†åˆ«ç»“æœ - æ™ºèƒ½åˆå¹¶å’Œå»é‡"""
        processed_results = []
        height, width = image_shape[:2]
        
        # ç»Ÿè®¡å±è”½è¿‡æ»¤ä¿¡æ¯
        total_results = len(results)
        masked_count = 0
        
        # ç¬¬ä¸€è½®ï¼šåŸºç¡€å¤„ç†å’Œç­›é€‰
        initial_results = []
        for result in results:
            # è§£æç»“æœæ ¼å¼ [bbox, text, confidence, method_id]
            if len(result) >= 3:
                bbox, text, confidence = result[0], result[1], result[2]
                method_id = result[3] if len(result) > 3 else "unknown"
            else:
                continue
            
            # è®¡ç®—è¾¹ç•Œæ¡†ä¿¡æ¯
            bbox_array = np.array(bbox)
            center_x = int(np.mean(bbox_array[:, 0]))
            center_y = int(np.mean(bbox_array[:, 1]))
            bbox_width = int(np.max(bbox_array[:, 0]) - np.min(bbox_array[:, 0]))
            bbox_height = int(np.max(bbox_array[:, 1]) - np.min(bbox_array[:, 1]))
            
            # å±è”½åŒºåŸŸè¿‡æ»¤ - æ£€æŸ¥è¾¹ç•Œæ¡†æ˜¯å¦åœ¨å±è”½åŒºåŸŸå†…
            if self.masked_regions and self._is_bbox_in_masked_region(bbox):
                masked_count += 1
                continue  # è·³è¿‡å±è”½åŒºåŸŸå†…çš„è¯†åˆ«ç»“æœ
            
            # åŠ¨æ€ç½®ä¿¡åº¦é˜ˆå€¼
            min_confidence = self._get_dynamic_confidence_threshold(text, bbox)
            if confidence < min_confidence:
                continue
                
            # æ¸…ç†æ–‡æœ¬
            clean_text = self._clean_text(text)
            if not clean_text or len(clean_text.strip()) < 1:
                continue
            
            # è¿‡æ»¤å¤ªå°çš„æ£€æµ‹ç»“æœï¼ˆå¯èƒ½æ˜¯å™ªå£°ï¼‰
            if bbox_width < 8 or bbox_height < 6:
                continue
            
            # è¯†åˆ«æ–‡æœ¬ç±»å‹
            text_type = self._classify_mechanical_text(clean_text)
            
            initial_results.append({
                'text': clean_text,
                'confidence': confidence,
                'center_x': center_x,
                'center_y': center_y,
                'bbox_width': bbox_width,
                'bbox_height': bbox_height,
                'bbox': bbox,
                'text_type': text_type,
                'original_text': text,
                'method_id': method_id
            })
        
        # æ‰“å°å±è”½ç»Ÿè®¡ä¿¡æ¯
        if self.masked_regions:
            print(f"ğŸš« å±è”½åŒºåŸŸè¿‡æ»¤: {masked_count}/{total_results} ä¸ªè¯†åˆ«ç»“æœè¢«å±è”½")
        
        # ç¬¬äºŒè½®ï¼šå»é‡å’Œåˆå¹¶
        processed_results = self._merge_duplicate_detections(initial_results)
        
        # ç¬¬ä¸‰è½®ï¼šä¸Šä¸‹æ–‡ä¼˜åŒ–
        processed_results = self._apply_context_optimization(processed_results)
        
        return processed_results
    
    def _get_dynamic_confidence_threshold(self, text, bbox):
        """æ ¹æ®æ–‡æœ¬å†…å®¹å’Œæ¡†å¤§å°åŠ¨æ€ç¡®å®šç½®ä¿¡åº¦é˜ˆå€¼"""
        # åŸºç¡€é˜ˆå€¼
        base_threshold = 0.25
        
        # æ ¹æ®æ–‡æœ¬é•¿åº¦è°ƒæ•´
        text_length = len(text.strip())
        if text_length == 1:
            return 0.45  # å•å­—ç¬¦éœ€è¦æ›´é«˜ç½®ä¿¡åº¦
        elif text_length == 2:
            return 0.35  # åŒå­—ç¬¦éœ€è¦ä¸­ç­‰ç½®ä¿¡åº¦
        elif text_length <= 4:
            return 0.3   # çŸ­æ–‡æœ¬
        
        # æ ¹æ®è¾¹ç•Œæ¡†å¤§å°è°ƒæ•´
        bbox_array = np.array(bbox)
        bbox_area = (np.max(bbox_array[:, 0]) - np.min(bbox_array[:, 0])) * \
                   (np.max(bbox_array[:, 1]) - np.min(bbox_array[:, 1]))
        
        if bbox_area < 150:  # å°å­—ä½“éœ€è¦æ›´é«˜ç½®ä¿¡åº¦
            return base_threshold + 0.1
        elif bbox_area > 1000:  # å¤§å­—ä½“å¯ä»¥æ”¾å®½è¦æ±‚
            return max(base_threshold - 0.05, 0.2)
        
        return base_threshold
    
    def _merge_duplicate_detections(self, results):
        """æ™ºèƒ½åˆå¹¶é‡å¤æ£€æµ‹çš„æ–‡æœ¬ - å¢å¼ºç‰ˆå»é‡"""
        if not results:
            return results
        
        print(f"ğŸ”„ å¼€å§‹å»é‡å¤„ç†ï¼ŒåŸå§‹ç»“æœæ•°é‡: {len(results)}")
        
        # ç¬¬ä¸€æ­¥ï¼šåŸºäºä½ç½®çš„ç²—ç•¥å»é‡
        position_grouped = {}
        for result in results:
            # ä½¿ç”¨ç½‘æ ¼åŒ–çš„ä½ç½®ä½œä¸ºé”®ï¼Œå‡å°‘å¾®å°åç§»çš„å½±å“
            grid_x = round(result['center_x'] / 20) * 20  # 20åƒç´ ç½‘æ ¼
            grid_y = round(result['center_y'] / 20) * 20  # 20åƒç´ ç½‘æ ¼
            grid_key = (grid_x, grid_y)
            
            if grid_key not in position_grouped:
                position_grouped[grid_key] = []
            position_grouped[grid_key].append(result)
        
        # ç¬¬äºŒæ­¥ï¼šåœ¨æ¯ä¸ªç½‘æ ¼å†…è¿›è¡Œç²¾ç»†å»é‡
        merged_results = []
        for grid_key, grid_results in position_grouped.items():
            if len(grid_results) == 1:
                # ç½‘æ ¼å†…åªæœ‰ä¸€ä¸ªç»“æœï¼Œç›´æ¥æ·»åŠ 
                merged_results.append(grid_results[0])
            else:
                # ç½‘æ ¼å†…æœ‰å¤šä¸ªç»“æœï¼Œéœ€è¦å»é‡
                grid_merged = self._merge_grid_results(grid_results)
                merged_results.extend(grid_merged)
        
        print(f"âœ… å»é‡å®Œæˆï¼Œæœ€ç»ˆç»“æœæ•°é‡: {len(merged_results)}")
        return merged_results
    
    def _merge_grid_results(self, grid_results):
        """åˆå¹¶ç½‘æ ¼å†…çš„é‡å¤ç»“æœ"""
        if len(grid_results) <= 1:
            return grid_results
        
        merged = []
        used_indices = set()
        
        for i, result1 in enumerate(grid_results):
            if i in used_indices:
                continue
            
            # å¯»æ‰¾ä¸å½“å‰ç»“æœç›¸ä¼¼çš„å…¶ä»–ç»“æœ
            similar_results = [result1]
            used_indices.add(i)
            
            for j, result2 in enumerate(grid_results[i+1:], i+1):
                if j in used_indices:
                    continue
                
                # æ£€æŸ¥ä½ç½®ç›¸ä¼¼æ€§ï¼ˆæ›´ä¸¥æ ¼çš„è·ç¦»æ£€æŸ¥ï¼‰
                distance = ((result1['center_x'] - result2['center_x']) ** 2 + 
                           (result1['center_y'] - result2['center_y']) ** 2) ** 0.5
                
                # æ£€æŸ¥æ–‡æœ¬ç›¸ä¼¼æ€§
                text_similar = self._texts_similar(result1['text'], result2['text'])
                
                # æ£€æŸ¥è¾¹ç•Œæ¡†é‡å 
                overlap_ratio = self._calculate_bbox_overlap(result1['bbox'], result2['bbox'])
                
                # æ›´ä¸¥æ ¼çš„åˆå¹¶æ¡ä»¶
                should_merge = False
                
                if distance < 15 and text_similar:
                    # ä½ç½®å¾ˆè¿‘ä¸”æ–‡æœ¬ç›¸ä¼¼
                    should_merge = True
                elif overlap_ratio > 0.5:
                    # è¾¹ç•Œæ¡†å¤§é‡é‡å 
                    should_merge = True
                elif distance < 25 and overlap_ratio > 0.3 and text_similar:
                    # ä¸­ç­‰è·ç¦»ä½†æœ‰é‡å ä¸”æ–‡æœ¬ç›¸ä¼¼
                    should_merge = True
                
                if should_merge:
                    similar_results.append(result2)
                    used_indices.add(j)
            
            # åˆå¹¶ç›¸ä¼¼çš„ç»“æœ
            if len(similar_results) == 1:
                merged.append(similar_results[0])
            else:
                merged_result = self._merge_similar_results(similar_results)
                merged.append(merged_result)
        
        return merged
    
    def _merge_similar_results(self, similar_results):
        """åˆå¹¶ç›¸ä¼¼çš„ç»“æœ"""
        # é€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„ä½œä¸ºåŸºç¡€
        best_result = max(similar_results, key=lambda x: x['confidence'])
        
        # é€‰æ‹©æœ€é•¿ä¸”æœ‰æ„ä¹‰çš„æ–‡æœ¬
        best_text = best_result['text']
        for result in similar_results:
            if (len(result['text']) > len(best_text) and 
                result['confidence'] > 0.3 and
                result['confidence'] > best_result['confidence'] * 0.6):
                best_text = result['text']
        
        # ä½¿ç”¨æœ€é«˜çš„ç½®ä¿¡åº¦
        best_confidence = max(r['confidence'] for r in similar_results)
        
        # ä½¿ç”¨å¹³å‡ä½ç½®ï¼ˆæ›´ç¨³å®šï¼‰
        avg_x = sum(r['center_x'] for r in similar_results) / len(similar_results)
        avg_y = sum(r['center_y'] for r in similar_results) / len(similar_results)
        
        # åˆ›å»ºåˆå¹¶åçš„ç»“æœ
        merged = best_result.copy()
        merged['text'] = best_text
        merged['confidence'] = best_confidence
        merged['center_x'] = int(avg_x)
        merged['center_y'] = int(avg_y)
        
        return merged
    
    def _positions_close(self, result1, result2, threshold=50):
        """åˆ¤æ–­ä¸¤ä¸ªæ£€æµ‹ç»“æœçš„ä½ç½®æ˜¯å¦ç›¸è¿‘"""
        distance = ((result1['center_x'] - result2['center_x']) ** 2 + 
                   (result1['center_y'] - result2['center_y']) ** 2) ** 0.5
        return distance < threshold
    
    def _calculate_bbox_overlap(self, bbox1, bbox2):
        """è®¡ç®—ä¸¤ä¸ªè¾¹ç•Œæ¡†çš„é‡å æ¯”ä¾‹"""
        bbox1_array = np.array(bbox1)
        bbox2_array = np.array(bbox2)
        
        x1_min, y1_min = np.min(bbox1_array, axis=0)
        x1_max, y1_max = np.max(bbox1_array, axis=0)
        
        x2_min, y2_min = np.min(bbox2_array, axis=0)
        x2_max, y2_max = np.max(bbox2_array, axis=0)
        
        # è®¡ç®—äº¤é›†
        inter_x_min = max(x1_min, x2_min)
        inter_y_min = max(y1_min, y2_min)
        inter_x_max = min(x1_max, x2_max)
        inter_y_max = min(y1_max, y2_max)
        
        if inter_x_max <= inter_x_min or inter_y_max <= inter_y_min:
            return 0.0
        
        inter_area = (inter_x_max - inter_x_min) * (inter_y_max - inter_y_min)
        
        # è®¡ç®—å¹¶é›†
        area1 = (x1_max - x1_min) * (y1_max - y1_min)
        area2 = (x2_max - x2_min) * (y2_max - y2_min)
        union_area = area1 + area2 - inter_area
        
        return inter_area / union_area if union_area > 0 else 0.0
    
    def _texts_similar(self, text1, text2):
        """åˆ¤æ–­ä¸¤ä¸ªæ–‡æœ¬æ˜¯å¦ç›¸ä¼¼"""
        text1_clean = text1.strip().lower()
        text2_clean = text2.strip().lower()
        
        # å®Œå…¨ç›¸åŒ
        if text1_clean == text2_clean:
            return True
        
        # ä¸€ä¸ªæ˜¯å¦ä¸€ä¸ªçš„å­ä¸²
        if text1_clean in text2_clean or text2_clean in text1_clean:
            return True
        
        # ç¼–è¾‘è·ç¦»åˆ¤æ–­
        max_len = max(len(text1_clean), len(text2_clean))
        if max_len <= 3:
            return abs(len(text1_clean) - len(text2_clean)) <= 1
        
        distance = self._levenshtein_distance(text1_clean, text2_clean)
        similarity = 1 - distance / max_len
        
        return similarity > 0.75
    
    def _levenshtein_distance(self, s1, s2):
        """è®¡ç®—ç¼–è¾‘è·ç¦»"""
        if len(s1) > len(s2):
            s1, s2 = s2, s1
        
        distances = range(len(s1) + 1)
        for i2, c2 in enumerate(s2):
            distances_ = [i2 + 1]
            for i1, c1 in enumerate(s1):
                if c1 == c2:
                    distances_.append(distances[i1])
                else:
                    distances_.append(1 + min((distances[i1], distances[i1 + 1], distances_[-1])))
            distances = distances_
        return distances[-1]
    
    def _apply_context_optimization(self, results):
        """åº”ç”¨ä¸Šä¸‹æ–‡ä¼˜åŒ–"""
        optimized_results = []
        
        for result in results:
            # ä¼˜åŒ–ç‰¹å®šç±»å‹çš„æ–‡æœ¬
            if result['text_type'] == 'number':
                # æ•°å­—ä¼˜åŒ–ï¼šç§»é™¤éæ•°å­—å­—ç¬¦
                number_match = re.search(r'\d+\.?\d*', result['text'])
                if number_match:
                    result['text'] = number_match.group()
            
            elif result['text_type'] == 'thread_spec':
                # èºçº¹è§„æ ¼ä¼˜åŒ–
                result['text'] = self._optimize_thread_spec(result['text'])
            
            elif result['text_type'] == 'diameter':
                # ç›´å¾„æ ‡æ³¨ä¼˜åŒ–
                result['text'] = self._optimize_diameter_notation(result['text'])
            
            elif result['text_type'] == 'dimension':
                # å°ºå¯¸æ ‡æ³¨ä¼˜åŒ–
                result['text'] = self._optimize_dimension_notation(result['text'])
            
            # é‡æ–°åˆ†ç±»ï¼ˆå¯èƒ½å› ä¸ºä¼˜åŒ–è€Œæ”¹å˜ï¼‰
            result['text_type'] = self._classify_mechanical_text(result['text'])
            
            if result['text'].strip():  # ç¡®ä¿ä¼˜åŒ–åä»æœ‰å†…å®¹
                optimized_results.append(result)
        
        return optimized_results
    
    def _optimize_thread_spec(self, text):
        """ä¼˜åŒ–èºçº¹è§„æ ¼è¯†åˆ«"""
        # å¸¸è§çš„èºçº¹è§„æ ¼æ¨¡å¼
        patterns = [
            r'M(\d+(?:\.\d+)?)',  # M8, M10, M12.5 ç­‰
            r'(\d+)M',            # åå‘è¯†åˆ«ï¼š8M -> M8
            r'M(\d+)[xXÃ—](\d+(?:\.\d+)?)',  # M8Ã—1.25
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                if pattern.startswith('M'):
                    if len(match.groups()) == 2:
                        return f"M{match.group(1)}Ã—{match.group(2)}"
                    else:
                        return f"M{match.group(1)}"
                else:
                    return f"M{match.group(1)}"
        
        return text
    
    def _optimize_diameter_notation(self, text):
        """ä¼˜åŒ–ç›´å¾„æ ‡æ³¨è¯†åˆ«"""
        # æå–æ•°å­—éƒ¨åˆ†
        numbers = re.findall(r'\d+\.?\d*', text)
        if numbers:
            return f"Î¦{numbers[0]}"
        return text
    
    def _optimize_dimension_notation(self, text):
        """ä¼˜åŒ–å°ºå¯¸æ ‡æ³¨è¯†åˆ«"""
        # æ ‡å‡†åŒ–ä¹˜å·
        text = re.sub(r'[xX*]', 'Ã—', text)
        # æ ‡å‡†åŒ–æ­£è´Ÿå·
        text = re.sub(r'[Â±+\-]', 'Â±', text)
        return text
    
    def _final_result_filtering(self, results):
        """æœ€ç»ˆç»“æœç­›é€‰å’Œæ’åº"""
        if not results:
            return results
        
        # æŒ‰ç½®ä¿¡åº¦å’Œæ–‡æœ¬ç±»å‹é‡è¦æ€§æ’åº
        type_priority = {
            'thread_spec': 10,      # èºçº¹è§„æ ¼æœ€é‡è¦
            'diameter': 9,          # ç›´å¾„æ ‡æ³¨
            'dimension': 8,         # å°ºå¯¸æ ‡æ³¨
            'tolerance': 7,         # å…¬å·®ç­‰çº§
            'surface_roughness': 6, # è¡¨é¢ç²—ç³™åº¦
            'angle': 5,             # è§’åº¦æ ‡æ³¨
            'material': 4,          # ææ–™æ ‡è®°
            'surface_treatment': 3, # è¡¨é¢å¤„ç†
            'geometry': 2,          # å‡ ä½•ç‰¹å¾
            'measurement': 1.5,     # æµ‹é‡å€¼
            'number': 1,            # çº¯æ•°å€¼
            'position': 0.8,        # ä½ç½®æ ‡è®°
            'label': 0.6,           # æ ‡ç­¾
            'annotation': 0.4       # æ™®é€šæ ‡æ³¨
        }
        
        # è®¡ç®—ç»¼åˆå¾—åˆ†
        for result in results:
            type_score = type_priority.get(result['text_type'], 0)
            confidence_score = result['confidence']
            
            # æ–‡æœ¬é•¿åº¦å¥–åŠ±ï¼ˆé€‚ä¸­é•¿åº¦çš„æ–‡æœ¬æ›´å¯èƒ½æ˜¯æœ‰æ•ˆä¿¡æ¯ï¼‰
            text_len = len(result['text'])
            length_score = 1.0
            if 2 <= text_len <= 12:
                length_score = 1.3
            elif text_len == 1:
                length_score = 0.7
            elif text_len > 20:
                length_score = 0.8
            
            # æ–‡æœ¬å¤æ‚åº¦å¥–åŠ±ï¼ˆåŒ…å«ç‰¹æ®Šç¬¦å·çš„æ–‡æœ¬æ›´é‡è¦ï¼‰
            complexity_score = 1.0
            special_chars = ['Î¦', 'Ã—', 'Â°', 'Â±', 'M', 'R']
            if any(char in result['text'] for char in special_chars):
                complexity_score = 1.2
            
            # ç»¼åˆå¾—åˆ†
            result['final_score'] = (type_score * 0.4 + confidence_score * 0.3 + 
                                   length_score * 0.2 + complexity_score * 0.1)
        
        # æŒ‰å¾—åˆ†æ’åº
        results.sort(key=lambda x: x['final_score'], reverse=True)
        
        # è¿‡æ»¤ä½åˆ†ç»“æœ
        min_score = 0.4  # é™ä½é˜ˆå€¼ä»¥ä¿ç•™æ›´å¤šå¯èƒ½æœ‰ç”¨çš„ç»“æœ
        filtered_results = [r for r in results if r['final_score'] >= min_score]
        
        return filtered_results
    
    def _clean_text(self, text):
        """æ¸…ç†è¯†åˆ«çš„æ–‡æœ¬ - å¢å¼ºç‰ˆ"""
        # ç§»é™¤å¤šä½™ç©ºæ ¼å’Œæ¢è¡Œç¬¦
        text = re.sub(r'\s+', ' ', text.strip())
        
        # ä¿®æ­£å¸¸è§çš„OCRé”™è¯¯ï¼ˆé’ˆå¯¹æœºæ¢°å›¾çº¸ï¼‰
        corrections = {
            # ç›´å¾„ç¬¦å·ä¿®æ­£
            'Î¦': 'Î¦', 'âˆ…': 'Î¦', 'Ã¸': 'Î¦', 'O': 'Î¦', '0': 'Î¦',
            'â‘ ': 'Î¦', 'â—¯': 'Î¦', 'â—‹': 'Î¦',
            
            # èºçº¹æ ‡è®°ä¿®æ­£
            'M': 'M', 'W': 'M', 'N': 'M', 'H': 'M',
            
            # æ•°å­—ä¿®æ­£
            'I': '1', 'l': '1', '|': '1', 'S': '5', 'G': '6', 'B': '8', 'g': '9',
            'O': '0', 'o': '0', 'D': '0',
            
            # ç¬¦å·ä¿®æ­£
            'Ã—': 'Ã—', 'x': 'Ã—', 'X': 'Ã—', '*': 'Ã—',
            'Â°': 'Â°', 'o': 'Â°', 'Ëš': 'Â°', 'ã€‚': 'Â°',
            
            # å°æ•°ç‚¹ä¿®æ­£
            ',': '.', 'Â·': '.', 'ï½¡': '.',
            
            # è¿æ¥ç¬¦ä¿®æ­£
            '-': '-', 'â€”': '-', 'â€“': '-', '_': '-',
        }
        
        # åº”ç”¨ä¿®æ­£
        for wrong, correct in corrections.items():
            text = text.replace(wrong, correct)
        
        # ç‰¹æ®Šå¤„ç†ï¼šèºçº¹è§„æ ¼ä¿®æ­£
        thread_patterns = [
            (r'(\d+)(\s*)[MmWwNnHh]', r'M\1'),  # æ•°å­—åè·Ÿå­—æ¯
            (r'[MmWwNnHh](\s*)(\d+)', r'M\2'),  # å­—æ¯åè·Ÿæ•°å­—
        ]
        
        for pattern, replacement in thread_patterns:
            text = re.sub(pattern, replacement, text)
        
        # ç‰¹æ®Šå¤„ç†ï¼šç›´å¾„æ ‡æ³¨ä¿®æ­£
        diameter_patterns = [
            (r'([Î¦Î¦âˆ…Ã¸â—‹â—¯â‘ OG0D])(\s*)(\d+\.?\d*)', r'Î¦\3'),  # ç¬¦å·åè·Ÿæ•°å­—
            (r'(\d+\.?\d*)(\s*)([Î¦Î¦âˆ…Ã¸â—‹â—¯â‘ OG0D])', r'Î¦\1'),  # æ•°å­—åè·Ÿç¬¦å·
        ]
        
        for pattern, replacement in diameter_patterns:
            text = re.sub(pattern, replacement, text)
        
        # æ¸…ç†å¤šä½™çš„ç©ºæ ¼å’Œæ ‡ç‚¹
        text = re.sub(r'\s+', ' ', text.strip())
        text = re.sub(r'([a-zA-Z])(\d)', r'\1\2', text)  # å­—æ¯å’Œæ•°å­—ä¹‹é—´ä¸è¦ç©ºæ ¼
        text = re.sub(r'(\d)([a-zA-Z])', r'\1\2', text)  # æ•°å­—å’Œå­—æ¯ä¹‹é—´ä¸è¦ç©ºæ ¼
        
        return text
    
    def _classify_mechanical_text(self, text):
        """åˆ†ç±»æœºæ¢°å›¾çº¸æ–‡æœ¬ç±»å‹ - å¢å¼ºç‰ˆ"""
        clean_text = text.strip()
        
        # 1. èºçº¹è§„æ ¼ (æœ€é«˜ä¼˜å…ˆçº§)
        thread_patterns = [
            r'^M\d+(?:\.\d+)?(?:\s*[xXÃ—]\s*\d+(?:\.\d+)?)?$',  # M8, M10, M12Ã—1.5
            r'^M\d+(?:\.\d+)?(?:-\d+(?:\.\d+)?)?$',          # M8-1.25
            r'^\d+M$',                                        # 8Mæ ¼å¼
        ]
        for pattern in thread_patterns:
            if re.match(pattern, clean_text, re.IGNORECASE):
                return 'thread_spec'
        
        # 2. ç›´å¾„æ ‡æ³¨
        diameter_patterns = [
            r'^Î¦\d+(?:\.\d+)?$',           # Î¦8, Î¦10.5
            r'^âˆ…\d+(?:\.\d+)?$',           # âˆ…8
            r'^Ã¸\d+(?:\.\d+)?$',           # Ã¸8
            r'^\d+(?:\.\d+)?Î¦$',           # 8Î¦æ ¼å¼
        ]
        for pattern in diameter_patterns:
            if re.match(pattern, clean_text):
                return 'diameter'
        
        # 3. å¤åˆå°ºå¯¸æ ‡æ³¨
        dimension_patterns = [
            r'^\d+(?:\.\d+)?\s*[Ã—xX]\s*\d+(?:\.\d+)?$',                    # 20Ã—30
            r'^\d+(?:\.\d+)?\s*[Ã—xX]\s*\d+(?:\.\d+)?\s*[Ã—xX]\s*\d+(?:\.\d+)?$',  # 20Ã—30Ã—40
            r'^\d+(?:\.\d+)?[-]\d+(?:\.\d+)?$',                              # 20-30
            r'^\d+(?:\.\d+)?\+\d+(?:\.\d+)?$',                             # 20+0.5
            r'^\d+(?:\.\d+)?Â±\d+(?:\.\d+)?$',                              # 20Â±0.1
        ]
        for pattern in dimension_patterns:
            if re.match(pattern, clean_text):
                return 'dimension'
        
        # 4. è§’åº¦æ ‡æ³¨
        angle_patterns = [
            r'^\d+(?:\.\d+)?Â°$',           # 30Â°, 45.5Â°
            r'^\d+(?:\.\d+)?\s*åº¦$',       # 30åº¦
            r'^\d+(?:\.\d+)?â€²$',           # 30â€² (åˆ†)
            r'^\d+(?:\.\d+)?â€³$',           # 30â€³ (ç§’)
        ]
        for pattern in angle_patterns:
            if re.match(pattern, clean_text):
                return 'angle'
        
        # 5. è¡¨é¢ç²—ç³™åº¦
        roughness_patterns = [
            r'^Ra\d+(?:\.\d+)?$',          # Ra3.2
            r'^Rz\d+(?:\.\d+)?$',          # Rz12.5
            r'^R[aznqtpv]\d+(?:\.\d+)?$',  # å„ç§è¡¨é¢ç²—ç³™åº¦
        ]
        for pattern in roughness_patterns:
            if re.match(pattern, clean_text, re.IGNORECASE):
                return 'surface_roughness'
        
        # 6. å…¬å·®ç­‰çº§
        tolerance_patterns = [
            r'^[ABCDEFGH]\d+$',            # A1, B2, H7ç­‰
            r'^[a-h]\d+$',                 # a1, b2, h7ç­‰
            r'^IT\d+$',                    # IT7, IT8ç­‰
        ]
        for pattern in tolerance_patterns:
            if re.match(pattern, clean_text):
                return 'tolerance'
        
        # 7. çº¯æ•°å€¼
        number_patterns = [
            r'^\d+(?:\.\d+)?$',            # 20, 30.5
            r'^\d+(?:\.\d+)?mm$',          # 20mm, 30.5mm
        ]
        for pattern in number_patterns:
            if re.match(pattern, clean_text):
                return 'number'
        
        # 8. ææ–™æ ‡è®°
        material_keywords = [
            # ä¸­æ–‡ææ–™
            'é’¢', 'é“', 'é“œ', 'é“', 'ä¸é”ˆé’¢', 'ç¢³é’¢', 'åˆé‡‘é’¢', 'é“¸é“', 'é“¸é’¢',
            'é»„é“œ', 'é’é“œ', 'ç´«é“œ', 'é”Œåˆé‡‘', 'é•åˆé‡‘', 'é’›åˆé‡‘',
            # è‹±æ–‡ææ–™
            'steel', 'iron', 'copper', 'aluminum', 'aluminium', 'brass', 'bronze',
            'stainless', 'carbon', 'alloy', 'cast', 'zinc', 'magnesium', 'titanium',
            # ææ–™ç‰Œå·
            'Q235', 'Q345', '45#', '20#', '16Mn', '304', '316', '201',
        ]
        for material in material_keywords:
            if material.lower() in clean_text.lower():
                return 'material'
        
        # 9. è¡¨é¢å¤„ç†
        surface_keywords = [
            # ä¸­æ–‡è¡¨é¢å¤„ç†
            'é•€é”Œ', 'å‘é»‘', 'é˜³ææ°§åŒ–', 'å–·æ¶‚', 'ç”µé•€', 'çƒ­å¤„ç†', 'æ·¬ç«', 'å›ç«',
            'æ¸—ç¢³', 'æ°®åŒ–', 'ç£·åŒ–', 'é’åŒ–', 'æŠ›å…‰', 'å–·ç ‚', 'ç”µæ³³', 'ç²‰æœ«å–·æ¶‚',
            # è‹±æ–‡è¡¨é¢å¤„ç†
            'zinc', 'black', 'anodize', 'coating', 'plating', 'treatment',
            'hardening', 'tempering', 'carburizing', 'nitriding', 'phosphating',
            'passivation', 'polishing', 'sandblasting', 'powder', 'painting',
        ]
        for surface in surface_keywords:
            if surface.lower() in clean_text.lower():
                return 'surface_treatment'
        
        # 10. å‡ ä½•ç‰¹å¾
        geometry_keywords = [
            # ä¸­æ–‡å‡ ä½•ç‰¹å¾
            'å­”', 'æ§½', 'å°', 'é¢', 'è¾¹', 'è§’', 'åœ†', 'æ–¹', 'å…­è§’', 'å†…å…­è§’',
            'å¤–å…­è§’', 'èŠ±é”®', 'é”®æ§½', 'èºçº¹', 'é”¥åº¦', 'å€’è§’', 'åœ†è§’', 'æ²‰å¤´',
            # è‹±æ–‡å‡ ä½•ç‰¹å¾
            'hole', 'slot', 'face', 'edge', 'corner', 'round', 'square', 'hex',
            'hexagon', 'spline', 'keyway', 'thread', 'taper', 'chamfer', 'fillet',
        ]
        for geometry in geometry_keywords:
            if geometry.lower() in clean_text.lower():
                return 'geometry'
        
        # 11. ä½ç½®æ ‡è®°
        position_keywords = [
            'å·¦', 'å³', 'ä¸Š', 'ä¸‹', 'å‰', 'å', 'å†…', 'å¤–', 'ä¸­å¿ƒ', 'ä¸­å¤®',
            'left', 'right', 'top', 'bottom', 'front', 'rear', 'inner', 'outer', 'center',
            'A', 'B', 'C', 'D', 'E', 'F',  # å¸¸è§çš„ä½ç½®æ ‡è®°
        ]
        if len(clean_text) <= 3 and any(pos in clean_text for pos in position_keywords):
            return 'position'
        
        # 12. æ ‡é¢˜å’Œè¯´æ˜
        title_keywords = [
            'å›¾', 'è§†å›¾', 'å‰–é¢', 'æ–­é¢', 'è¯¦å›¾', 'å±€éƒ¨', 'æ”¾å¤§', 'æ¯”ä¾‹',
            'view', 'section', 'detail', 'scale', 'fig', 'figure',
            'æ ‡é¢˜', 'è¯´æ˜', 'å¤‡æ³¨', 'æ³¨æ„', 'è¦æ±‚',
            'title', 'note', 'remark', 'attention', 'requirement',
        ]
        for title in title_keywords:
            if title.lower() in clean_text.lower():
                return 'title'
        
        # 13. æ£€æŸ¥æ˜¯å¦ä¸ºå•ä¸ªå­—ç¬¦ï¼ˆå¯èƒ½æ˜¯æ ‡è®°ï¼‰
        if len(clean_text) == 1:
            if clean_text.isalpha():
                return 'label'
            elif clean_text.isdigit():
                return 'number'
            else:
                return 'symbol'
        
        # 14. æ£€æŸ¥æ˜¯å¦åŒ…å«å•ä½
        unit_patterns = [
            r'\d+(?:\.\d+)?\s*mm',  # æ•°å­—+mm
            r'\d+(?:\.\d+)?\s*cm',  # æ•°å­—+cm
            r'\d+(?:\.\d+)?\s*m',   # æ•°å­—+m
            r'\d+(?:\.\d+)?\s*Â°',   # æ•°å­—+åº¦
        ]
        for pattern in unit_patterns:
            if re.search(pattern, clean_text, re.IGNORECASE):
                return 'measurement'
        
        # é»˜è®¤åˆ†ç±»
        return 'annotation'
    
    def _is_bbox_in_masked_region(self, bbox) -> bool:
        """æ£€æŸ¥è¾¹ç•Œæ¡†æ˜¯å¦åœ¨å±è”½åŒºåŸŸå†…"""
        if not self.masked_regions:
            return False
        
        # è®¡ç®—è¾¹ç•Œæ¡†çš„çŸ©å½¢
        bbox_array = np.array(bbox)
        x_min, y_min = np.min(bbox_array, axis=0)
        x_max, y_max = np.max(bbox_array, axis=0)
        
        # æ£€æŸ¥ä¸­å¿ƒç‚¹æ˜¯å¦åœ¨å±è”½åŒºåŸŸå†…
        center_x = (x_min + x_max) / 2
        center_y = (y_min + y_max) / 2
        
        # å¤„ç†å­—å…¸æ ¼å¼çš„å±è”½åŒºåŸŸæ•°æ®
        for region in self.masked_regions:
            if isinstance(region, dict):
                # å­—å…¸æ ¼å¼: {'x': x, 'y': y, 'width': w, 'height': h}
                rx = region.get('x', 0)
                ry = region.get('y', 0)
                rw = region.get('width', 0)
                rh = region.get('height', 0)
                
                if rx <= center_x <= rx + rw and ry <= center_y <= ry + rh:
                    return True
            elif hasattr(region, 'contains'):
                # QRectFå¯¹è±¡
                if region.contains(center_x, center_y):
                    return True
            elif hasattr(region, '__getitem__') and len(region) >= 4:
                # åæ ‡æ•°ç»„ [x, y, width, height]
                rx, ry, rw, rh = region[0], region[1], region[2], region[3]
                if rx <= center_x <= rx + rw and ry <= center_y <= ry + rh:
                    return True
        
        return False 